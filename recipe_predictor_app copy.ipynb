{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Import Libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Embedding, LSTM, Dropout, BatchNormalization, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define Constants\n",
    "IMG_SIZE = 128  # Size to which images will be resized\n",
    "MAX_SEQUENCE_LENGTH = 50  # Max length of the recipes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load and Preprocess Data\n",
    "# Load the merged CSV file\n",
    "data = pd.read_csv('merged_recipes_with_images.csv')\n",
    "\n",
    "# Prepare a dictionary to hold images for each recipe\n",
    "recipe_images = {}\n",
    "\n",
    "# Iterate through the data to group images by recipes\n",
    "for index, row in data.iterrows():\n",
    "    recipe = row['Recipe']  # Adjust based on your CSV column name\n",
    "    images = row['Image Paths'].split(', ')  # Update to use the correct column name\n",
    "\n",
    "    if recipe not in recipe_images:\n",
    "        recipe_images[recipe] = []\n",
    "    recipe_images[recipe].extend(images)\n",
    "\n",
    "# Prepare dataset for CNN\n",
    "X_images = []\n",
    "y_recipes = []\n",
    "\n",
    "for recipe, images in recipe_images.items():\n",
    "    for image_path in images:\n",
    "        img = load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
    "        img_array = img_to_array(img) / 255.0  # Normalize the images\n",
    "        X_images.append(img_array)\n",
    "        y_recipes.append(recipe)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_images = np.array(X_images)\n",
    "y_recipes = np.array(y_recipes)\n",
    "\n",
    "# Convert y_recipes to categorical labels\n",
    "y_recipes_unique, y_recipes_encoded = np.unique(y_recipes, return_inverse=True)\n",
    "num_classes = len(y_recipes_unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Split Dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_images, y_recipes_encoded, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! Cell 5: Build CNN Model initial \n",
    "# def create_cnn_model(input_shape, num_classes):\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(128, activation='relu'))\n",
    "#     model.add(Dense(num_classes, activation='softmax'))\n",
    "#     return model\n",
    "\n",
    "#! rakesh dropout\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))  # Dropout after first max pooling\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))  # Dropout after second max pooling\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))  # Dropout before the final output layer\n",
    "    \n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "#!  CNN Model for Image Classification\n",
    "# def create_cnn_model(input_shape, num_classes):\n",
    "#     model = Sequential()\n",
    "    \n",
    "#     # First Convolutional Block\n",
    "#     model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#     # Second Convolutional Block\n",
    "#     model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "#     # Third Convolutional Block (Additional)\n",
    "#     model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "#     model.add(Flatten())\n",
    "    \n",
    "#     # Fully Connected Layers\n",
    "#     model.add(Dense(256, activation='relu'))\n",
    "#     model.add(Dropout(0.5))  # Increased dropout for better generalization\n",
    "    \n",
    "#     model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# Create the CNN model\n",
    "cnn_model = create_cnn_model(X_train.shape[1:], num_classes)\n",
    "print(cnn_model.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Compile and Train the Model\n",
    "cnn_model.compile(optimizer=Adam(), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = cnn_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Plot Training History\n",
    "# plt.plot(history.history['accuracy'], label='accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract data from the history object\n",
    "history_dict = history.history\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "accuracy = history_dict['accuracy']\n",
    "val_accuracy = history_dict['val_accuracy']\n",
    "\n",
    "# Create an epochs range\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, accuracy, 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Save the Model\n",
    "cnn_model.save('cnn_model_3.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv('merged_recipes_with_images.csv')\n",
    "\n",
    "# Assuming the column with recipes is named 'Recipe'\n",
    "recipes = data['Recipe'].values  # Make sure this column exists in your CSV\n",
    "\n",
    "# Initialize the Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(recipes)\n",
    "\n",
    "# Get the vocabulary size (+1 for padding token)\n",
    "vocab_size = len(tokenizer.word_index) + 1  \n",
    "\n",
    "# Set the maximum sequence length (can be adjusted based on your data)\n",
    "max_sequence_length = 50  \n",
    "\n",
    "# Convert recipes to sequences of integers\n",
    "sequences = tokenizer.texts_to_sequences(recipes)\n",
    "\n",
    "# Pad the sequences to ensure they all have the same length\n",
    "sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Prepare the target variable (y_recipes_lstm)\n",
    "# Assuming y_recipes_lstm should be the labels shifted by one word\n",
    "# y_recipes_lstm should represent the next word to predict\n",
    "# It will take the sequences and use all but the first element as the target\n",
    "y_recipes_lstm = np.array([seq[1:] for seq in sequences])  # Target is the sequence shifted by one\n",
    "y_recipes_lstm = np.eye(vocab_size)[y_recipes_lstm]  # Convert to one-hot encoding\n",
    "\n",
    "# Reshape y_recipes_lstm to match the expected shape\n",
    "# This ensures that the shape is (samples, timesteps, features)\n",
    "y_recipes_lstm = y_recipes_lstm.reshape(-1, max_sequence_length - 1, vocab_size)  # Adjusting timesteps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Build LSTM Model initial model arch.\n",
    "# def create_lstm_model(input_shape, num_classes):\n",
    "#     model = Sequential()\n",
    "#     model.add(Embedding(input_dim=num_classes, output_dim=128, input_length=input_shape[1]))\n",
    "#     model.add(LSTM(128, return_sequences=False))\n",
    "#     model.add(Dense(num_classes, activation='softmax'))\n",
    "#     return model\n",
    "\n",
    "#? rakesh dropout\n",
    "# def create_lstm_model(input_shape, num_classes):\n",
    "#     model = Sequential()\n",
    "#     model.add(Embedding(input_dim=num_classes, output_dim=128, input_length=input_shape[1]))\n",
    "#     model.add(LSTM(128, return_sequences=False))\n",
    "#     model.add(Dropout(0.5))  # Dropout layer to reduce overfitting\n",
    "#     model.add(Dense(num_classes, activation='softmax'))    \n",
    "#     return model\n",
    "\n",
    "#? improvement after rakesh\n",
    " \n",
    "# def create_lstm_model(input_shape, vocab_size):\n",
    "#     model = Sequential()\n",
    "    \n",
    "#     # Embedding Layer\n",
    "#     model.add(Embedding(input_dim=vocab_size, output_dim=256, input_length=input_shape[1]))\n",
    "    \n",
    "#     # Bidirectional LSTM for Better Sequence Learning\n",
    "#     model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "#     model.add(Dropout(0.25))\n",
    "    \n",
    "#     # Another LSTM Layer for More Depth\n",
    "#     model.add(LSTM(128, return_sequences=False))\n",
    "#     model.add(Dropout(0.25))\n",
    "    \n",
    "#     # Fully Connected Layer\n",
    "#     model.add(Dense(128, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "    \n",
    "#     model.add(Dense(vocab_size, activation='softmax'))\n",
    "    \n",
    "#     return model\n",
    "# # Create the LSTM model\n",
    "# lstm_model = create_lstm_model(sequences.shape, len(tokenizer.word_index) + 1)\n",
    "\n",
    "# print(lstm_model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the merged CSV file\n",
    "data = pd.read_csv('merged_recipes_with_images.csv')\n",
    "\n",
    "# Prepare a dictionary to hold images and recipes\n",
    "recipe_images = {}\n",
    "recipe_texts = {}\n",
    "\n",
    "# Iterate through the data to group images by recipes and collect recipe texts\n",
    "for index, row in data.iterrows():\n",
    "    recipe = row['Recipe']  # Adjust based on your CSV column name\n",
    "    images = row['Image Paths'].split(', ')  # Adjust based on your CSV column name\n",
    "    recipe_text = row['Recipe']  # Assuming you have a column for recipe text\n",
    "\n",
    "    # Store images\n",
    "    if recipe not in recipe_images:\n",
    "        recipe_images[recipe] = []\n",
    "    recipe_images[recipe].extend(images)\n",
    "\n",
    "    # Store recipe text\n",
    "    recipe_texts[recipe] = recipe_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the tokenizer for the recipe texts\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(recipe_texts.values())  # Fit tokenizer on all recipe texts\n",
    "\n",
    "# Convert texts to sequences\n",
    "sequences = tokenizer.texts_to_sequences(recipe_texts.values())\n",
    "\n",
    "# Pad the sequences to ensure uniform input size\n",
    "sequences = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "# Convert the sequences to the format required for LSTM\n",
    "# Use the previous sequences as input and the next word as the target\n",
    "X_recipes = []\n",
    "y_recipes_lstm = []\n",
    "\n",
    "for seq in sequences:\n",
    "    for i in range(1, len(seq)):\n",
    "        X_recipes.append(seq[:i])  # Previous words\n",
    "        y_recipes_lstm.append(seq[i])  # Next word\n",
    "\n",
    "# Pad the sequences for LSTM input\n",
    "X_recipes = pad_sequences(X_recipes, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_recipes = np.array(X_recipes)\n",
    "y_recipes_lstm = np.array(y_recipes_lstm)\n",
    "\n",
    "# Convert y_recipes_lstm to categorical labels\n",
    "y_recipes_lstm = to_categorical(y_recipes_lstm, num_classes=len(tokenizer.word_index) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model\n",
    "#def create_lstm_model(input_shape, num_classes):\n",
    "    #model = Sequential()\n",
    "    #model.add(Embedding(input_dim=num_classes, output_dim=128, input_length=input_shape[1]))\n",
    "    #model.add(LSTM(128, return_sequences=True))\n",
    "   # model.add(LSTM(64))\n",
    "  #  model.add(Dense(num_classes, activation='softmax'))\n",
    " #   return model\n",
    "\n",
    "# Create the LSTM model\n",
    "#lstm_model = create_lstm_model(X_recipes.shape, len(tokenizer.word_index) + 1)\n",
    "\n",
    "# Compile the model\n",
    "#lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the LSTM model\n",
    "#history_lstm = lstm_model.fit(X_recipes, y_recipes_lstm, validation_split=0.2, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Dropout\n",
    "\n",
    "# def create_lstm_model(input_shape, num_classes):\n",
    "#     model = Sequential()\n",
    "#     model.add(Embedding(input_dim=10000, output_dim=128, input_length=input_shape[1]))  # Adjust parameters as needed\n",
    "#     model.add(LSTM(128, return_sequences=True))\n",
    "#     model.add(Dropout(0.25))  # Add dropout layer after LSTM\n",
    "#     model.add(LSTM(64))  # You can adjust this layer as necessary\n",
    "#     model.add(Dropout(0.5))  # Add another dropout layer\n",
    "#     model.add(Dense(num_classes, activation='softmax'))\n",
    "#     return model\n",
    "\n",
    "#  #Create the LSTM model\n",
    "# lstm_model = create_lstm_model(X_recipes.shape, len(tokenizer.word_index) + 1)\n",
    "\n",
    "def create_lstm_model(input_shape, vocab_size):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Embedding Layer\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=256, input_length=input_shape[1]))\n",
    "    \n",
    "    # Bidirectional LSTM for Better Sequence Learning\n",
    "    model.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    # Another LSTM Layer for More Depth\n",
    "    model.add(LSTM(128, return_sequences=False))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    # Fully Connected Layer\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "# Create the LSTM model\n",
    "lstm_model = create_lstm_model(X_recipes.shape, len(tokenizer.word_index) + 1)\n",
    "print(lstm_model.summary())\n",
    "# lstm_model = create_lstm_model(sequences.shape, len(tokenizer.word_index) + 1)\n",
    "\n",
    "# Compile the model\n",
    "lstm_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the LSTM model\n",
    "history_lstm = lstm_model.fit(X_recipes, y_recipes_lstm, validation_split=0.2, epochs=50, batch_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract data from history\n",
    "history_dict = history_lstm.history\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "accuracy = history_dict['accuracy']\n",
    "val_accuracy = history_dict['val_accuracy']\n",
    "\n",
    "# Create epochs range\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, accuracy, 'b', label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the LSTM model\n",
    "lstm_model.save('lstm_model_3.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
